# PPO agent configuration
name: ppo

# Core training parameters
total_timesteps: 1000000
learning_rate: 3e-4
num_envs: 1
num_steps: 2048
anneal_lr: true

# PPO algorithm parameters
gamma: 0.99
gae_lambda: 0.95
num_minibatches: 32
update_epochs: 10
norm_adv: true
clip_coef: 0.2
clip_vloss: true
ent_coef: 0.0
vf_coef: 0.5
max_grad_norm: 0.5
target_kl: null

# Network architecture
hidden_size: 64
actor_std_init: 0.01

# Training settings
torch_deterministic: true
cuda: true

# Logging settings
tf_log: true
tf_log_dir: "runs"